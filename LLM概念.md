# 模型
```mermaid

flowchart LR
A[推理模型]
B[传统模型]
C[大型模型]
D[小型模型]
A1[效率慢、成本高、擅长理解复杂任务和多步骤规划、生成内部思维链]
B1[效率高、成本低、通常需要明确的指令、更复杂的提示词、更多的提示工程技巧]
C1[参数量>100B+，跨领域理解提示和解决复杂问题]
D1[参数两<10B、经济高效，小模型也可以使用大模型的结果进行微调训练这个过程叫做蒸馏以在特定任务中提升性能]

A-->A1
B-->B1
C-->C1
D-->D1
```

# 提示工程
又名 提示词工程，指为模型生成内容创建有效指令的过程，因为模型生成的内容通常是非确定性的，所以构建一个从模型生成正确内容的提示是艺术和科学的结合。
提示工程的通用指导原则
+ 为模型提供输入、输出的类型以及相应的示例（少样本学习）
+ 在指令中详细说明模型应该如何回复、以消除歧义
+ 当使用推理模型时，从目标和期望的结果两方面描述要完成的任务，而不是分布说明如何完成任务
+ 为prompt创建评测，最好使用真实数据或等价的数据来测试。

# 流式输出
流式传输是一种持续传输数据块的通信方式，与传统请求——响应模型不同，响应数据可分块发送。
**典型应用场景**  
+ 直播
+ 日志实时监控
+ 大模型生成文本模拟打字机效果

要了解流式输出，需要先了解长链接。长链接（Long Connection）是指在一次连接建立后，在一段时间内保持连接状态，持续进行数据传输，而不是每次传输数据都重新建立连接。与短链接相比，长链接减少了连接建立和断开的开销，适用于需要频繁交互的场景。
在HTTP/1.1协议中，默认支持长链接。通过在请求头中设置Connection: keep-alive，客户端和服务器可以在一次TCP连接上进行多次HTTP请求和响应，而不需要每次都重新建立TCP连接

**HTTP长链接**  
|技术|特点|适用场景|
|---|---|---|
|polling|定时轮询服务器|简单实时通知|
|long polling|保持连接直到又数据或超时|中等实时性需求|
|SSE|服务器单向推送事件流|实时数据更新|
|websocket|双向全双工通信|即时聊天、游戏|

**服务器发送事件-SSE**  
服务器发送事件（Server - Sent Events，SSE）是一种允许服务器向客户端实时推送更新的Web API。与传统的HTTP请求 - 响应模式不同，SSE建立一个长连接，服务器可以在有新数据时随时向客户端发送事件。客户端通过监听特定的事件流来接收数据。SSE使用text/event-stream MIME类型，以文本格式发送数据

**大模型为什么需要流式输出**  
当大模型生成长文本响应内容时，传统模式需要等待全部生成完成一次性返回，而使用流式输出的好处有：
+ 首字响应时间降低、实现打字机效果
+ 支持中间干预（如停止生成）
+ 防止超时断开连接

# 多模态：图片、语音、视频
多模态 指的是多种信息形式的结合，比如图片、音频、视频等。而多模态模型则是能够同时理解和处理这些不同形式信息的人工智能模型。它就像一个“全能型选手”，能够像人类一样同时处理视觉、听觉和语言信息，从而实现更复杂的任务。

## 图片处理
+ 通过URL传递图像
+ 通过base64编码传递图像

## 语音处理
+ 语音代理：通过理解音频来处理任务，并以自然语言进行回应
+ 流式音频： 实时处理音频，构建语音代理和其他低延迟应用，包括转录用例
+ 文本到语音：要将文本转换为语音，使用音频 API的 audio/speech 端点
+ 语音到文本：要将语音转换为文本，使用音频 API 的 audio/transcriptions 端点
+ 控制脚本与模型对话：要将语音转换为文本，使用音频 API 的 audio/transcriptions 端点

## 视频处理
+ 视频理解：通过多模态模型对视频内容进行理解和提取信息的过程，其输入可以是文字、图像、音频等多种模态的信息，或者他们的混合，输出通常是文本
+ 视频生成：通过多模态模型根据输入的文本、图像或其他信息，自动生成对应的视频内容，这种技术的核心在于将非视频信息转化为动态、连贯的视觉内容。其输入可以是文字、图像、视频等，输出通常为视频

**视频理解**  
多模态模型处理视频内容的核心思路是将视频转换为模型可理解的形式，通常通过抽帧（将视频分解为连续的图像帧）并结合其他模态（如文本、音频）进行综合分析和理解。

主要功能：
+ 视频内容理解​：识别视频中的场景、物体、人物、动作等
+ 关键帧提取​：从视频中提取关键帧，帮助快速获取视频的主要内容
+ 动作识别​：分析视频中的人物动作或物体运动
​+ 场景分割​：将视频分割成不同场景或片段，便于后续处理
+ 语音识别与字幕生成​：提取视频中的语音内容并生成字幕
+ 情绪分析​：分析视频中人物的情绪或视频整体的情感基调

应用场景：
+ 视频分类​：自动分类视频内容，例如将视频分为“体育”“教育”“娱乐”等类别
+ 内容审核​：快速检测视频中是否存在违规内容（如暴力、色情等）
+ 广告推荐​：根据视频内容推荐相关广告
+ 视频剪辑工具​：自动提取视频中的关键内容，帮助用户快速剪辑视频

**视频生成**  
主要功能：
+ 文本驱动生成​：用户只需输入一段文字描述，即可自动生成对应的视频内容，无需复杂的操作或手动调整
+ 多模态融合​：整合了视觉、语言等多种模态信息，能够更精准地理解文本描述，并生成符合预期的视频
+ 高效处理​：通过优化算法和模型结构，在生成视频时表现出较高的效率，适用于实时或快速生成的需求
+ ​高质量输出​：生成的视频在画面质量、动作连贯性和场景真实性方面表现出色，具备较高的视觉效果

应用场景：
+ 影视制作​：创作者可以通过简单的文字描述快速生成视频片段，加速制作流程
+ 教育培训​：用于制作教学视频或演示，提升教学内容的可视化效果
+ 广告创意​：帮助企业快速生成广告视频，提高创意表现力
+ 游戏开发​：辅助生成游戏场景或角色动作，加快开发周期

# 对话状态管理
对话状态管理是与AI模型交互中的关键环节。通过合理管理对话状态，可以在多轮对话中保持信息的连贯性，从而提升用户体验

**手动管理对话状态**  
尽管每次文本生成请求都是独立的，但开发者可以通过在请求参数中添加历史消息来实现多轮对话
可以在一次请求中捕获对话的前一个状态，从而实现多轮对话的管理。为了手动共享上下文，可以将模型的上一个回复作为输入的一部分，并将其附加到下一个请求中，可以实现对话的连续性

**上下文窗口管理**  
指的是模型在单次请求中可以处理的最大令牌数，包括输入、输出以及用于推理的令牌数。每种模型都有不同的上下文窗口限制
在处理复杂输入或包含多轮对话的请求时，需要特别注意输出令牌和上下文窗口的限制。模型在生成响应时，会根据输入的复杂程度消耗不同数量的令牌。如果输入的上下文过多，可能会导致超出上下文窗口的限制，从而影响输出的质量和完整性

上下文窗口的令牌计算包括以下部分
+ 输入令牌：用户输入内容
+ 输出令牌：模型响应内容
+ 推理令牌：模型用于规划响应的内部计算

如果生成的令牌数量超过了上下文窗口的限制，超出部分可能会被截断，从而影响最终的输出结果

# 分词器与对话模板

+ 为什么需要 chat-template?：大型语言模型（LLMs）在处理对话时，都有自己期望的特定输入格式。例如，即便两个模型都基于相似的架构，如 Mistral 和 Zephyr，它们在训练过程中可能采用了完全不同的对话格式。某些模型可能要求对话以特定角色标签（如 [INST] 和 [/INST]）包裹，而另一些可能使用特殊的标记（如 <|user|>、<|assistant|>) 来区分发言者
  - 多样性挑战：每个模型都有其独特的对话格式
  - 复杂性： 手动构建这些复杂而精确的格式既耗时又容易出错
  - 性能影响：错误的格式会导致模型性能显著下降， 模型没有在错误的格式上进行训练，可能无法理解输入意图
+ chat-template的定义与作用： 它是一种用于将人类可读的对话历史转换为模型能够理解的单一可标记化字符串的标准、鲁棒的方式。当您加载一个预训练的对话模型时，其对应的 tokenizer（标记器）通常会自带一个与该模型训练时所用格式相匹配的 chat-template
  - 统一格式： 自动化将结构化的对话（如列表）转换为模型所需的特定字符串格式
  - 避免错误： 大大减少手动格式化可能引入的错误
  - 提升性能：确保模型接收到其训练时期望的精确格式，从而最大化模型性能和一致性

**chat-template高级应用与定制**  
+ 多模板场景： 复杂模型可能设计不止一个chat-template，以适应不同的使用场景
  - 默认模板： 用于一般的对话交互
  - 工具使用模板（tool_use）：专门用于模型调用外部工具的特定格式
  - 检索增强生成模板（rag）：结合了检索到的信息，需要在输入中以特定方式呈现

# 函数调用
大模型函数调用是一种强大的能力，允许大型语言模型 (LLM) 与外部工具或 API 交互，从而扩展其功能并解决更复杂的问题。 简单来说，就是让LLM不仅能理解和生成文本，还能调用函数来完成实际操作

**核心思想**  
+ LLM生成指令：当用户提出的问题需要外部工具或API解决时，LLM会识别出这种需求，并生成一个包含函数名称和参数的指令
+ 执行函数：该指令被传递给相应的外部工具或 API，执行相应的操作
+ 返回结果：工具或API将执行结果返回给LLM
+ LLM整合结果：LLM将接收到的结果整合到其回复中，提供给用户一个完整，有用的答案

**工作流程**  
+ 预定义函数：使用 JSON Schema 定义函数，包括名称、描述、参数和参数类型
+ 发送请求：将函数定义和用户输入一起发送到 OpenAI API
+ 处理响应：API 会返回一个 JSON 对象，指示是否需要调用函数，以及需要调用的函数名称和参数
+ 执行函数：根据 API 返回的函数名称和参数，执行相应的函数
+ 返回结果：将函数执行结果发送回 OpenAI API
+ 生成最终回复：API 会将函数执行结果整合到回复中，并返回给用户

**使用场景**  
+ 获取天气
+ 发送邮件
+ 搜素知识库

```mermaid
sequenceDiagram
    autonumber
    participant A as 用户（Client）
    participant B as 大模型（LLM）
    participant C as 外部工具（API）

    %% 可以直接用别名替代
    Note left of A: 预定义函数
    Note over A, C: 函数调用示例
    loop 获取天气函数调用序列图
        Note right of A: LLM生成指令
        A -->>+ B: 西安今天天气如何?
        B -->>- A: 返回需要调用的函数信息 {"function":"get_weather", "city":"西安"}
        rect rgb(240, 255, 255)
        A -->> C: 执行函数 get_weather("西安")
        activate C
        C -->> A: 返回函数执行结果 {"temp":"25°C", "condition":"晴"}
        deactivate C
        end
        A -->>+ B: 将函数结果发送给模型
        B -->>- A: 西安今天晴天，气温25摄氏度
    end
```
